{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "228b123c",
   "metadata": {},
   "source": [
    "### Secure tool calling with Arcade.dev\n",
    "\n",
    "This notebook is going to close one of the biggest gaps between demo and production agents: Secure tool-calling\n",
    "\n",
    "When your agents work well in your computer, they are excellent personal assistants, but scaling that up to many users is not easy, as the security assumptions from a local deployment do not apply to agents at scale. Personal Access Tokens simply won't cut it for multiple users. Even if you encapsulate all of the functionality in a remote MCP server, tool-level auth will require you to implement the auth flow for all the providers that your agent relies on.\n",
    "\n",
    "Arcade solves this by providing a unified platform for agentic tool calling and execution. It will handle the auth flow for you offering a secure multi-user solution for your agents.\n",
    "\n",
    "In this notebook we will learn how to use Arcade and LangGraph to :-\n",
    "\n",
    "- Build agents\n",
    "- Give tools that can interact with\n",
    "    - GMail\n",
    "    - Slack\n",
    "    - Notion\n",
    "- Implement safety guardrails when calling specific tools (Human-in-the-Loop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac951e8",
   "metadata": {},
   "source": [
    "## Development Environment Setup\n",
    "\n",
    "Before implementing our multi-user agent system, we need to establish a proper development environment with the necessary dependencies. The following installation includes LangGraph for agent orchestration, LangChain-Arcade for tool integration, and the core LangChain library with OpenAI support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b333abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(40696) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages (1.0.4)\n",
      "Requirement already satisfied: langchain-openai in /Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages (1.0.2)\n",
      "Requirement already satisfied: langgraph in /Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages (1.0.2)\n",
      "Requirement already satisfied: langchain-arcade in /Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages (1.4.4)\n",
      "Requirement already satisfied: python-dotenv in /Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages (1.2.1)\n",
      "Collecting langchain-core<2.0.0,>=1.0.0 (from langchain)\n",
      "  Downloading langchain_core-1.0.4-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages (from langchain) (2.12.4)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages (from langchain-openai) (2.7.1)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages (from langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages (from langgraph) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages (from langgraph) (1.0.2)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages (from langgraph) (0.2.9)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages (from langgraph) (3.6.0)\n",
      "Requirement already satisfied: arcadepy>=1.7.0 in /Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages (from langchain-arcade) (1.9.0)\n",
      "INFO: pip is looking at multiple versions of langchain-arcade to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-arcade\n",
      "  Using cached langchain_arcade-1.3.1-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting arcadepy==1.3.* (from langchain-arcade)\n",
      "  Using cached arcadepy-1.3.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting langchain-arcade\n",
      "  Using cached langchain_arcade-1.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "  Using cached langchain_arcade-1.2.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting arcadepy==1.1.* (from langchain-arcade)\n",
      "  Using cached arcadepy-1.1.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting langchain-arcade\n",
      "  Using cached langchain_arcade-1.1.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "  Using cached langchain_arcade-1.0.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "  Using cached langchain_arcade-0.1.2-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting arcadepy<0.2.0,>=0.1.2 (from langchain-arcade)\n",
      "  Using cached arcadepy-0.1.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting langchain-arcade\n",
      "  Using cached langchain_arcade-0.1.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "INFO: pip is still looking at multiple versions of langchain-arcade to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached langchain_arcade-0.1.0-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting langgraph\n",
      "  Downloading langgraph-1.0.3-py3-none-any.whl.metadata (7.8 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached langgraph-1.0.2-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting langchain-openai\n",
      "  Using cached langchain_openai-1.0.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "  Using cached langchain_openai-1.0.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "  Using cached langchain_openai-1.0.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "  Using cached langchain_openai-0.3.35-py3-none-any.whl.metadata (2.4 kB)\n",
      "INFO: pip is looking at multiple versions of langchain-openai to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached langchain_openai-0.3.34-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Using cached langchain_openai-0.3.33-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Using cached langchain_openai-0.3.32-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Using cached langchain_openai-0.3.31-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Using cached langchain_openai-0.3.30-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Using cached langchain_openai-0.3.29-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Using cached langchain_openai-0.3.28-py3-none-any.whl.metadata (2.3 kB)\n",
      "INFO: pip is still looking at multiple versions of langchain-openai to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached langchain_openai-0.3.27-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Using cached langchain_openai-0.3.26-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Using cached langchain_openai-0.3.25-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Using cached langchain_openai-0.3.24-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Using cached langchain_openai-0.3.23-py3-none-any.whl.metadata (2.3 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached langchain_openai-0.3.22-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Using cached langchain_openai-0.3.21-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Using cached langchain_openai-0.3.20-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Using cached langchain_openai-0.3.19-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Using cached langchain_openai-0.3.18-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Using cached langchain_openai-0.3.17-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Using cached langchain_openai-0.3.16-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Using cached langchain_openai-0.3.15-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Using cached langchain_openai-0.3.14-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Using cached langchain_openai-0.3.13-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Using cached langchain_openai-0.3.12-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Using cached langchain_openai-0.3.11-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Using cached langchain_openai-0.3.10-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Using cached langchain_openai-0.3.9-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Using cached langchain_openai-0.3.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Using cached langchain_openai-0.3.7-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Using cached langchain_openai-0.3.6-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Using cached langchain_openai-0.3.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Using cached langchain_openai-0.3.4-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Using cached langchain_openai-0.3.3-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Using cached langchain_openai-0.3.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Using cached langchain_openai-0.3.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Using cached langchain_openai-0.3.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Using cached langchain_openai-0.2.14-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Using cached langchain_openai-0.2.13-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Using cached langchain_openai-0.2.12-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Using cached langchain_openai-0.2.11-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Using cached langchain_openai-0.2.10-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Using cached langchain_openai-0.2.9-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Using cached langchain_openai-0.2.8-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Using cached langchain_openai-0.2.7-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Using cached langchain_openai-0.2.6-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Using cached langchain_openai-0.2.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Using cached langchain_openai-0.2.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Using cached langchain_openai-0.2.3-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Using cached langchain_openai-0.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Using cached langchain_openai-0.2.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Using cached langchain_openai-0.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Using cached langchain_openai-0.1.25-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Using cached langchain_openai-0.1.24-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Using cached langchain_openai-0.1.23-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Using cached langchain_openai-0.1.22-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Using cached langchain_openai-0.1.20-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Using cached langchain_openai-0.1.19-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Using cached langchain_openai-0.1.17-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Using cached langchain_openai-0.1.16-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Using cached langchain_openai-0.1.15-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Using cached langchain_openai-0.1.14-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Using cached langchain_openai-0.1.13-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Using cached langchain_openai-0.1.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Using cached langchain_openai-0.1.11-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Using cached langchain_openai-0.1.10-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Using cached langchain_openai-0.1.9-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Using cached langchain_openai-0.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Using cached langchain_openai-0.1.7-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Using cached langchain_openai-0.1.6-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Using cached langchain_openai-0.1.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Using cached langchain_openai-0.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Using cached langchain_openai-0.1.3-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Using cached langchain_openai-0.1.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Using cached langchain_openai-0.1.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Using cached langchain_openai-0.0.8-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Using cached langchain_openai-0.0.7-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Using cached langchain_openai-0.0.6-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Using cached langchain_openai-0.0.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Using cached langchain_openai-0.0.4-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Using cached langchain_openai-0.0.3-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Using cached langchain_openai-0.0.2.post1-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Using cached langchain_openai-0.0.2-py3-none-any.whl.metadata (570 bytes)\n",
      "Collecting langchain\n",
      "  Downloading langchain-1.0.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (0.4.41)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (4.15.0)\n",
      "  Using cached langchain-1.0.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Using cached langchain-1.0.3-py3-none-any.whl.metadata (4.7 kB)\n",
      "  Using cached langchain-1.0.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting langgraph\n",
      "  Using cached langgraph-1.0.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "  Using cached langgraph-1.0.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
      "  Using cached langgraph_checkpoint-2.1.2-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langchain\n",
      "  Using cached langchain-1.0.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "  Using cached langchain-1.0.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "  Using cached langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages (from langchain) (0.3.79)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.3.11-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Using cached sqlalchemy-2.0.44-cp312-cp312-macosx_10_13_x86_64.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages (from langchain) (2.32.5)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages (from arcadepy>=1.7.0->langchain-arcade) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages (from arcadepy>=1.7.0->langchain-arcade) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages (from arcadepy>=1.7.0->langchain-arcade) (0.28.1)\n",
      "Requirement already satisfied: sniffio in /Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages (from arcadepy>=1.7.0->langchain-arcade) (1.3.1)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in /Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph) (1.12.0)\n",
      "INFO: pip is looking at multiple versions of langgraph-prebuilt to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph)\n",
      "  Using cached langgraph_checkpoint-3.0.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "  Using cached langgraph_checkpoint-3.0.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "  Using cached langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
      "  Using cached langgraph_checkpoint-2.1.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.3.10-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting pip>=25.2 (from langchain-text-splitters<1.0.0,>=0.3.9->langchain)\n",
      "  Using cached pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
      "INFO: pip is still looking at multiple versions of langgraph-prebuilt to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.3.9-py3-none-any.whl.metadata (1.9 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "Collecting langchain-arcade\n",
      "  Using cached langchain_arcade-1.4.4-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting langgraph\n",
      "  Using cached langgraph-0.2.76-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
      "  Using cached langgraph_sdk-0.1.74-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (0.25.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.11.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2025.10.5)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Using cached greenlet-3.2.4-cp312-cp312-macosx_11_0_universal2.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages (from httpx<1,>=0.23.0->arcadepy>=1.7.0->langchain-arcade) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->arcadepy>=1.7.0->langchain-arcade) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain) (3.0.0)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph)\n",
      "  Using cached langgraph_checkpoint-2.0.26-py3-none-any.whl.metadata (4.6 kB)\n",
      "  Using cached langgraph_checkpoint-2.0.25-py3-none-any.whl.metadata (4.6 kB)\n",
      "  Using cached langgraph_checkpoint-2.0.24-py3-none-any.whl.metadata (4.6 kB)\n",
      "  Using cached langgraph_checkpoint-2.0.23-py3-none-any.whl.metadata (4.6 kB)\n",
      "  Using cached langgraph_checkpoint-2.0.22-py3-none-any.whl.metadata (4.6 kB)\n",
      "  Using cached langgraph_checkpoint-2.0.21-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting msgpack<2.0.0,>=1.1.0 (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph)\n",
      "  Using cached msgpack-1.1.2-cp312-cp312-macosx_10_13_x86_64.whl.metadata (8.1 kB)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph)\n",
      "  Using cached langgraph_checkpoint-2.0.20-py3-none-any.whl.metadata (4.6 kB)\n",
      "  Using cached langgraph_checkpoint-2.0.19-py3-none-any.whl.metadata (4.6 kB)\n",
      "  Using cached langgraph_checkpoint-2.0.18-py3-none-any.whl.metadata (4.6 kB)\n",
      "  Using cached langgraph_checkpoint-2.0.17-py3-none-any.whl.metadata (4.6 kB)\n",
      "  Using cached langgraph_checkpoint-2.0.16-py3-none-any.whl.metadata (4.6 kB)\n",
      "  Using cached langgraph_checkpoint-2.0.15-py3-none-any.whl.metadata (4.6 kB)\n",
      "  Using cached langgraph_checkpoint-2.0.14-py3-none-any.whl.metadata (4.6 kB)\n",
      "  Using cached langgraph_checkpoint-2.0.13-py3-none-any.whl.metadata (4.6 kB)\n",
      "  Using cached langgraph_checkpoint-2.0.12-py3-none-any.whl.metadata (4.6 kB)\n",
      "  Using cached langgraph_checkpoint-2.0.10-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting langgraph\n",
      "  Using cached langgraph-0.2.75-py3-none-any.whl.metadata (17 kB)\n",
      "  Using cached langgraph-0.2.74-py3-none-any.whl.metadata (17 kB)\n",
      "  Using cached langgraph-0.2.73-py3-none-any.whl.metadata (17 kB)\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ac/Desktop/Github/Agents_in_Production/env_2/bin/pip3\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "             ^^^^^^\n",
      "  File \"/Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages/pip/_internal/cli/main.py\", line 79, in main\n",
      "    return command.main(cmd_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
      "    return self._main(args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages/pip/_internal/cli/base_command.py\", line 236, in _main\n",
      "    self.handle_pip_version_check(options)\n",
      "  File \"/Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages/pip/_internal/cli/req_command.py\", line 188, in handle_pip_version_check\n",
      "    pip_self_version_check(session, options)\n",
      "  File \"/Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages/pip/_internal/self_outdated_check.py\", line 231, in pip_self_version_check\n",
      "    installed_dist = get_default_environment().get_distribution(\"pip\")\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages/pip/_internal/metadata/importlib/_envs.py\", line 189, in get_distribution\n",
      "    return next(matches, None)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages/pip/_internal/metadata/importlib/_envs.py\", line 184, in <genexpr>\n",
      "    matches = (\n",
      "              ^\n",
      "  File \"/Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages/pip/_internal/metadata/base.py\", line 626, in iter_all_distributions\n",
      "    for dist in self._iter_distributions():\n",
      "  File \"/Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages/pip/_internal/metadata/importlib/_envs.py\", line 176, in _iter_distributions\n",
      "    yield from finder.find(location)\n",
      "  File \"/Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages/pip/_internal/metadata/importlib/_envs.py\", line 79, in find\n",
      "    for dist, info_location in self._find_impl(location):\n",
      "  File \"/Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages/pip/_internal/metadata/importlib/_envs.py\", line 64, in _find_impl\n",
      "    raw_name = get_dist_name(dist)\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ac/Desktop/Github/Agents_in_Production/env_2/lib/python3.12/site-packages/pip/_internal/metadata/importlib/_compat.py\", line 52, in get_dist_name\n",
      "    name = cast(Any, dist).name\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/importlib/metadata/__init__.py\", line 457, in name\n",
      "    return self.metadata['Name']\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/importlib/metadata/__init__.py\", line 452, in metadata\n",
      "    return _adapters.Message(email.message_from_string(text))\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/email/__init__.py\", line 37, in message_from_string\n",
      "    return Parser(*args, **kws).parsestr(s)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/email/parser.py\", line 64, in parsestr\n",
      "    return self.parse(StringIO(text), headersonly=headersonly)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/email/parser.py\", line 53, in parse\n",
      "    feedparser.feed(data)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/email/feedparser.py\", line 174, in feed\n",
      "    self._call_parse()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/email/feedparser.py\", line 178, in _call_parse\n",
      "    self._parse()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/email/feedparser.py\", line 462, in _parsegen\n",
      "    for line in self._input:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/email/feedparser.py\", line 128, in __next__\n",
      "    line = self.readline()\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/email/feedparser.py\", line 88, in readline\n",
      "    for ateof in reversed(self._eofstack):\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# !pip3 install langgraph langchain-arcade langchain langchain-openai\n",
    "# Install required packages\n",
    "!pip3 install langchain langchain-openai langgraph langchain-arcade python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9083b45",
   "metadata": {},
   "source": [
    "## API Key Configuration\n",
    "\n",
    "Our tutorial requires two essential API keys for operation. You will need an [OpenAI API](https://platform.openai.com/signup) key, as well as an [Arcade API](https://api.arcade.dev/signup?utm_source=github&utm_medium=notebook&utm_campaign=nir_diamant&utm_content=tutorial) key for this tutorial. Both services offer straightforward registration processes, with Arcade specifically designed to simplify the integration of external tools into AI applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2ea1e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file (create this with your API key)\n",
    "load_dotenv()\n",
    "\n",
    "# Set OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Set Arcade API key\n",
    "os.environ[\"ARCADE_API_KEY\"] = os.getenv('ARCADE_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bdd349",
   "metadata": {},
   "source": [
    "## User Identity Configuration\n",
    "\n",
    "The Arcade platform requires user identification to properly manage tool authorizations and maintain security boundaries between different users. This identifier must correspond to the email address used during Arcade account creation, ensuring that tool permissions and OAuth tokens are correctly associated with the appropriate user account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2296b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set ARCADE user id which is the email address used furing Arcade account creation\n",
    "os.environ[\"ARCADE_USER_ID\"] = os.getenv('ARCADE_USER_ID')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4e4423",
   "metadata": {},
   "source": [
    "# Simple Conversational Agent\n",
    "\n",
    "We begin our journey by implementing a basic conversational agent that demonstrates core LangGraph functionality without external tool dependencies. This foundational agent provides conversational capabilities with short-term memory, allowing it to maintain context throughout a conversation while establishing the architectural patterns we'll extend throughout this tutorial.\n",
    "\n",
    "## Core Agent Implementation\n",
    "\n",
    "The following implementation creates a ReAct-style agent using [LangGraph and Arcade](https://docs.arcade.dev/home/langchain/use-arcade-tools#create-a-react-style-agent?utm_source=github&utm_medium=notebook&utm_campaign=nir_diamant&utm_content=tutorial). We configure it with conversation memory through a MemorySaver checkpointer, enabling the agent to remember previous interactions within the same conversation thread. The agent receives a clear prompt defining its helpful and concise personality, along with instructions for handling unclear requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e1a3f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.messages import HumanMessage\n",
    "import uuid\n",
    "\n",
    "# create a checkpointer to persist the graph's state\n",
    "checkpointer = MemorySaver()\n",
    "\n",
    "agent_a = create_agent(\n",
    "    model=\"openai:gpt-5-mini\",\n",
    "    system_prompt=\"You are a helpful assistant that can help with everyday tasks.\"\n",
    "           \" If the user's request is confusing you must ask them to clarify\"\n",
    "           \" their intent, and fulfill the instruction to the best of your\"\n",
    "           \" ability. Be concise and friendly at all times.\",\n",
    "    tools=[], # no tools for now!\n",
    "    checkpointer=checkpointer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be10084c",
   "metadata": {},
   "source": [
    "## Agent Interaction Utility\n",
    "\n",
    "To facilitate consistent interaction with our agents throughout this tutorial, we implement a utility function that streams agent responses and displays them in a readable format. This function processes the graph's streaming output and presents the latest message from each interaction cycle, providing immediate feedback during agent conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "98a66c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph.state import CompiledStateGraph\n",
    "def run_graph(graph: CompiledStateGraph, config, input):\n",
    "    \n",
    "    for event in graph.stream(input, config=config, stream_mode=\"values\"):\n",
    "        if \"messages\" in event:\n",
    "            event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a409866",
   "metadata": {},
   "source": [
    "## Interactive Chat Interface\n",
    "\n",
    "The following implementation provides a complete interactive chat interface for testing our basic agent. The system generates a unique conversation thread identifier for each session, enabling memory persistence across multiple exchanges within the same conversation. Users can engage naturally with the agent and terminate the session by typing \"exit\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf85adca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, can you let me know about any open-source tools or libraries that can streamline the proces of auth flow for connect different APIs with LLMs?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Great â€” here are openâ€‘source tools and libraries, organized by role, that will speed up building and managing auth flows when connecting external APIs to LLMs (or any backend/agent):\n",
      "\n",
      "1) OAuth/OIDC client libraries (use to implement auth flows, refresh tokens, etc.)\n",
      "- Python: Authlib, requests-oauthlib â€” mature, support OAuth2/OIDC flows and token refresh.\n",
      "- Node.js: openid-client, simple-oauth2, passport.js (strategy ecosystem) â€” easy to wire into web apps.\n",
      "- Go: golang.org/x/oauth2 â€” standard, lightweight.\n",
      "- Java: Spring Security OAuth/OIDC â€” full-featured for Spring apps.\n",
      "\n",
      "2) Identity / Authorization servers (self-hosted providers for issuing tokens and managing users)\n",
      "- Keycloak â€” full OIDC/OAuth2 server, user federation, roles, consent screens.\n",
      "- ORY Hydra (plus ORY Kratos for user management) â€” cloud-native OAuth2/OIDC.\n",
      "- Dex â€” simple OIDC connector for Kubernetes and microservices.\n",
      "\n",
      "3) OAuth connectors / proxy / token orchestration (help expose many thirdâ€‘party APIs with OAuth without reimplementing for each)\n",
      "- Pizzly â€” open-source OAuth proxy/connector that centralizes OAuth for many APIs and returns tokens to your backend. Great when building many third-party connectors.\n",
      "- oauth2-proxy â€” protect services/resources behind an OAuth provider; useful to front endpoints that LLM agents call.\n",
      "- Airbyte (connectors) â€” ETL/connector platform; many connectors include built-in OAuth flows for data ingestion.\n",
      "\n",
      "4) Low-code/automation platforms with built-in connectors (fast way to integrate APIs + auth)\n",
      "- n8n â€” open-source workflow automation with many OAuth connectors; you can extend/connect to LLMs.\n",
      "- Huginn â€” event-driven agent workflows; supports API auth flows via scripts.\n",
      "\n",
      "5) Secrets & credential management (store tokens/keys securely)\n",
      "- HashiCorp Vault â€” secrets storage, dynamic credentials, encryption-as-a-service.\n",
      "- Mozilla SOPS / Sealed Secrets â€” encrypt secrets for GitOps and k8s.\n",
      "- Confidant â€” secret storage with access control.\n",
      "\n",
      "6) LLM / agent frameworks (for wiring tools that call external APIs)\n",
      "- LangChain â€” provides \"tools\" and agent patterns; you manage auth for the tool (token injection, refresh). Not an auth manager but integrates well with token stores/proxies.\n",
      "- LlamaIndex (now llamaintex) connectors â€” many connectors expect you to handle OAuth; combine with a connector manager or Pizzly.\n",
      "Note: Most LLM frameworks rely on you to supply valid credentials/tokens when defining tools. Use the above connector/proxy/secrets tools alongside them.\n",
      "\n",
      "7) Language-specific helpers and utilities\n",
      "- axios-oauth-client / grant (Node) â€” small utility helpers for flows.\n",
      "- requests-oauthlib (Python) â€” session-based token handling and refresh integration.\n",
      "\n",
      "Best practices for LLM+API auth\n",
      "- Never embed long-lived secrets into prompts or agent state. Keep tokens on server side.\n",
      "- Use a connector/proxy (Pizzly or a custom token service) so agents call a known backend endpoint; backend attaches tokens.\n",
      "- Use Vault (or similar) for storing tokens, and rotate/refresh tokens automatically.\n",
      "- Minimize OAuth scopes and implement revocation webhooks (if provider supports).\n",
      "- For per-user data access, store tokens per user and link to agent sessions; ensure consent and clear UI.\n",
      "\n",
      "Typical recommended stacks (examples)\n",
      "- Web app agent that calls userâ€™s Google/Calendar:\n",
      "  - Node: openid-client + Passport or Pizzly for connector; store tokens in Vault; LangChain agent calls your backend tool endpoint.\n",
      "- Batch ingestion to feed LLMs (data sync):\n",
      "  - Airbyte connectors or custom scripts using authlib / requests-oauthlib; secrets stored in Vault.\n",
      "- Self-hosted centralized auth for many microservices:\n",
      "  - Keycloak or ORY Hydra + Vault for secrets + oauth2-proxy to protect services.\n",
      "\n",
      "If you tell me: (a) your language/platform (Python/Node/Go), and (b) whether you need per-user OAuth or service-to-service API keys, I can suggest a concrete stack and a short code example for the auth flow.\n"
     ]
    }
   ],
   "source": [
    "# the configuration helps LangGraph keep track of conversations and interrups\n",
    "# While it's not needed for this agent. The agent will remember different\n",
    "# conversations based on the thread_id. This code generates a random id every\n",
    "# time you run the cell, but you can hardcode the thread_id if you want to\n",
    "# test the memory.\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": uuid.uuid4()\n",
    "    }\n",
    "}\n",
    "while True:\n",
    "    user_input = input(\"ðŸ‘¤: \")\n",
    "    # let's use \"exit\" as a safe way to break the infinite loop\n",
    "    if user_input.lower() == \"exit\":\n",
    "        break\n",
    "\n",
    "    user_message = {\"messages\": [HumanMessage(content=user_input)]}\n",
    "    run_graph(agent_a, config, user_message)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae2c37e",
   "metadata": {},
   "source": [
    "## Testing Agent Limitations / Demonstrating Authentication Requirements\n",
    "\n",
    "The following test illustrates the agent's complete inability to access private, authenticated data sources. When asked to summarize personal emails, the agent cannot proceed without proper authentication mechanisms and authorized access to external services. This limitation highlights the critical need for secure tool integration in production agent systems.\n",
    "\n",
    "To understand the boundaries of our basic agent, we'll test it with requests that require external data access. The following test demonstrates the agent's inability to provide current date information, as most language models lack real-time data access and may provide outdated or inaccurate temporal information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ccd9c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread_id = 055a7ebe-17ed-4e23-b9eb-fa2c5477658e\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "summarize my latest 3 emails please\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I donâ€™t have access to your inbox. If youâ€™d like me to summarize your latest three emails, please paste the emails (or the subject/sender/date and body for each) here â€” or forward the text of each message.\n",
      "\n",
      "How to paste (quick template you can copy for each email):\n",
      "- Subject:\n",
      "- From:\n",
      "- Date:\n",
      "- Body:\n",
      "\n",
      "Tell me which summary format you want:\n",
      "- Very short: one line per email (main point).\n",
      "- Short: 3â€“4 bullets per email (key points + one action).\n",
      "- Detailed: summary, action items, deadlines, suggested replies.\n",
      "\n",
      "Also tell me if you want:\n",
      "- Highlighted action items and deadlines\n",
      "- Suggested reply drafts for any messages\n",
      "- Priority ranking\n",
      "\n",
      "Paste the emails and your preferred format, and Iâ€™ll summarize them.\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": uuid.uuid4()\n",
    "    }\n",
    "}\n",
    "print(f'thread_id = {config[\"configurable\"][\"thread_id\"]}')\n",
    "\n",
    "prompt = \"summarize my latest 3 emails please\"\n",
    "user_message = {\"messages\": [HumanMessage(content=prompt)]}\n",
    "run_graph(agent_a, config, user_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52e3173",
   "metadata": {},
   "source": [
    "# Tool Integration with Secure Authentication\n",
    "\n",
    "Having established our basic agent architecture, we now address the core challenge of enabling secure access to external services. This section demonstrates how Arcade.dev solves the complex problem of tool-level authentication, providing a streamlined approach to OAuth integration that scales across multiple users and services.\n",
    "\n",
    "## Arcade Client Initialization\n",
    "\n",
    "We begin by establishing connections to the Arcade platform through both the core client and the LangChain integration layer. The ToolManager serves as our primary interface for configuring and authorizing tools, while the Arcade client handles the underlying authentication infrastructure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b543b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_arcade import ToolManager\n",
    "from arcadepy import Arcade\n",
    "\n",
    "arcade_client = Arcade(api_key=os.getenv(\"ARCADE_API_KEY\"))\n",
    "manager = ToolManager(client=arcade_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3fc7c9",
   "metadata": {},
   "source": [
    "## Gmail Tool Configuration\n",
    "\n",
    "Our first tool integration focuses on Gmail access, specifically the email listing capability that our basic agent could not provide. The Gmail_ListEmails tool enables our agent to retrieve and analyze email data, but requires proper user authorization before it can access private email accounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ee3405a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmail_tool = manager.init_tools(tools=[\"Gmail_ListEmails\"])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8950bd2",
   "metadata": {},
   "source": [
    "## Authorization Utility Function\n",
    "\n",
    "To streamline the authorization process throughout this tutorial, we implement a reusable function that handles OAuth flow initiation and completion. For reading our email, however, we need to give our app permissions to read it in a secure way. Arcade lets us do this easily by [handling the OAuth2 for us](https://docs.arcade.dev/home/auth/how-arcade-helps?utm_source=github&utm_medium=notebook&utm_campaign=nir_diamant&utm_content=tutorial). This function checks the current authorization status for a specific tool and user combination, initiating the OAuth process when necessary and waiting for user completion of the authorization flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d34fb27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def authorize_tool(tool_name, user_id, manager):\n",
    "    # This line will check if this user is authorized to use the\n",
    "    # tool, and return a response that we can use if the user\n",
    "    # did not authorize the tool yet.\n",
    "    auth_response = manager.authorize(\n",
    "        tool_name=tool_name,\n",
    "        user_id=user_id\n",
    "    )\n",
    "    if auth_response.status != \"completed\":\n",
    "        print(f\"The app wants to use the {tool_name} tool.\\n\"\n",
    "              f\"Please click this url to authorize it {auth_response.url}\")\n",
    "        # wait until the user authorizes\n",
    "        manager.wait_for_auth(auth_response.id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf47e679",
   "metadata": {},
   "source": [
    "## Gmail Authorization Process\n",
    "\n",
    "The following cell initiates the authorization process for Gmail access. If the user has not previously granted permissions, Arcade will provide an OAuth URL for completing the authorization. Once authorized, the permission persists for future sessions, eliminating the need for repeated authorization flows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a80c8cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "authorize_tool(gmail_tool.name, os.getenv(\"ARCADE_USER_ID\"), manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7706e0c",
   "metadata": {},
   "source": [
    "## Enhanced Agent with Gmail Capabilities\n",
    "\n",
    "With Gmail authorization complete, we can now create an enhanced agent that incorporates email access capabilities. This agent retains all the conversational abilities of our basic implementation while adding the power to interact with authenticated email services. Notice the updated prompt that explicitly mentions Gmail capabilities and the inclusion of the user_id in the configuration for tool execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e262457d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread_id = d062f6ce-0563-421e-a8b6-9de3a33ccba8\n",
      "user_id = abdullahmakhdoom1998@gmail.com\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "summarize my latest 3 emails please\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Gmail_ListEmails (call_za8N36pUOekT3W9fDDdLS0rf)\n",
      " Call ID: call_za8N36pUOekT3W9fDDdLS0rf\n",
      "  Args:\n",
      "    n_emails: 3\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: Gmail_ListEmails\n",
      "\n",
      "{\"emails\": [{\"body\": \"[image: Google] You allowed Arcade.dev access to some of your Google Account data abdullahmakhdoom1998@gmail.com If you didnâ€™t allow Arcade.dev access to some of your Google Account data, someone else may be trying to access your Google Account data. Take a moment now to check your account activity and secure your account. Check activity To make changes at any time to the access that Arcade.dev has to your data, go to your Google Account You can also see security activity at https://myaccount.google.com/notifications You received this email to let you know about important changes to your Google Account and services. Â© 2025 Google LLC, 1600 Amphitheatre Parkway, Mountain View, CA 94043, USA\", \"cc\": \"\", \"date\": \"Tuesday, November 11, 2025 at 19:02:38 UTC\", \"from\": \"Google <no-reply@accounts.google.com>\", \"header_message_id\": \"<WW8SDpZt0jQYRx-x38PXWg@notifications.google.com>\", \"history_id\": \"4432529\", \"id\": \"19a744c777972a25\", \"in_reply_to\": \"\", \"label_ids\": [\"UNREAD\", \"CATEGORY_UPDATES\", \"INBOX\"], \"references\": \"\", \"reply_to\": \"\", \"snippet\": \"You allowed Arcade.dev access to some of your Google Account data abdullahmakhdoom1998@gmail.com If you didn&#39;t allow Arcade.dev access to some of your Google Account data, someone else may be\", \"subject\": \"Security alert\", \"thread_id\": \"19a744c777972a25\", \"to\": \"abdullahmakhdoom1998@gmail.com\"}, {\"body\": \"The Positions for Foreign Workers are still open â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ [ASKMigration 2 logo] [1] WHICH CANADIAN CITY ARE YOU MOST INTERESTED IN ABDULLAH ? (PLEASE SELECT) [2] Toronto [2] Vancouver [3] Calgary [4] The Express Entry system is used by the federal government to manage permanent residence applications. Candidates earn points from their profiles based on their human capital factors such as age, work experience, and language proficiency in English and French. READY TO MOVE NOW? ðŸ‘ I'm Ready! [5] ðŸ‘‰ Show Me How! [5] [facebook social link] [6] You received this email because you subscribed to our list. You can unsubscribe [7] at any time. 1020 Rue Bouvier Suite 400, Quebec City, QC Quebec City Canada Links: ------ [1] https://askmigration.com [2] https://askmigration.com/toronto-is-quickly-becoming-a-city-of-immigrants/ [3] https://askmigration.com/high-likelihoods-of-canadian-immigrants-staying-in-vancouver-toronto-and-edmonton/ [4] https://askmigration.com/a-practical-guide-to-starting-your-life-in-calgary/ [5] https://askmigration.com/canadas-new-immigration-plan-a-strong-focus-on-in-canada-candidates/ [6] https://facebook.com/WorkInCanada [7] https://arborescens.eomail1.com/unsubscribe?ep=1&l=48f5fe54-9de8-11f0-b7aa-cd1ed697c951&lc=d2191a64-b6a6-11f0-b3fd-4947056edf74&p=129e89ee-be49-11f0-9b6b-61743f153398&pt=campaign&pv=4&spa=1762848942&t=1762883282&s=4220715ff5f1daf5752150033025eb60885b20fb60adc231ec7832ee5c310d9c\", \"cc\": \"\", \"date\": \"Tuesday, November 11, 2025 at 17:48:02 UTC\", \"from\": \"James <news@askmigration.com>\", \"header_message_id\": \"<0111019a740825a9-d463df23-083b-439f-b4ba-c1d49677b411-000000@us-west-1.amazonses.com>\", \"history_id\": \"4432317\", \"id\": \"19a7408272a6eeae\", \"in_reply_to\": \"\", \"label_ids\": [\"CATEGORY_PROMOTIONS\", \"UNREAD\", \"INBOX\"], \"references\": \"\", \"reply_to\": \"\", \"snippet\": \"The Positions for Foreign Workers are still open â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ ASKMigration 2 logo Which Canadian City are you\", \"subject\": \"Which Canadian City are you most Interested inÂ  Abdullah ?\", \"thread_id\": \"19a7408272a6eeae\", \"to\": \"Abdullah <abdullahmakhdoom1998@gmail.com>\"}, {\"body\": \"Do you know Rohan Manzoor?39 mutual connections Yes, connect: https://www.linkedin.com/comm/mynetwork/send-invite/rohan-manzoor/?lipi=urn%3Ali%3Apage%3Aemail_email_pymk_02%3BuaqwsqVBTnuiga3mlI0Qww%3D%3D&midSig=1SfoNaKTXakI01&midToken=AQHYQWW6cllYNQ&trkEmail=eml-email_pymk_02-pymkCard-0-pymk_cta%3A+urn%3Ali%3Amember%3A629546208-null-awbyzh%7Emhusu3sh%7Eu0-null-null&trk=eml-email_pymk_02-pymkCard-0-pymk_cta%3A+urn%3Ali%3Amember%3A629546208&_sig=34AZNlGhvbkI01 More people you may know Tooba Imtiaz Student Researcher at Google | EE PhD Candidate at Northeastern Researching on 3D computer vision, interpretable machine learning, and adversarial attacks. https://www.linkedin.com/comm/mynetwork/send-invite/tooba-imtiaz/?lipi=urn%3Ali%3Apage%3Aemail_email_pymk_02%3BuaqwsqVBTnuiga3mlI0Qww%3D%3D&midSig=1SfoNaKTXakI01&midToken=AQHYQWW6cllYNQ&trkEmail=eml-email_pymk_02-pymkCard-0-pymk_cta%3A+urn%3Ali%3Amember%3A485964087-null-awbyzh%7Emhusu3sh%7Eu0-null-null&trk=eml-email_pymk_02-pymkCard-0-pymk_cta%3A+urn%3Ali%3Amember%3A485964087&_sig=0W2QFuw8TbkI0140 mutual connections Syed Hassan Jalil Head of Engineering - Disperse https://www.linkedin.com/comm/mynetwork/send-invite/shjalil/?lipi=urn%3Ali%3Apage%3Aemail_email_pymk_02%3BuaqwsqVBTnuiga3mlI0Qww%3D%3D&midSig=1SfoNaKTXakI01&midToken=AQHYQWW6cllYNQ&trkEmail=eml-email_pymk_02-pymkCard-0-pymk_cta%3A+urn%3Ali%3Amember%3A187200048-null-awbyzh%7Emhusu3sh%7Eu0-null-null&trk=eml-email_pymk_02-pymkCard-0-pymk_cta%3A+urn%3Ali%3Amember%3A187200048&_sig=2nTDlUio7bkI0149 mutual connections Abdul Wajid Databricks Certified Data Engineer â€“ Professional | 2x Databricks Certified | Principal Data Engineer @ Confiz | Azure | ADF | Spark | Delta Lake | Cloudera | Lakehouse Architect | ETL Pipelines | End-to-End Solutions https://www.linkedin.com/comm/mynetwork/send-invite/abdul-wajid-de/?lipi=urn%3Ali%3Apage%3Aemail_email_pymk_02%3BuaqwsqVBTnuiga3mlI0Qww%3D%3D&midSig=1SfoNaKTXakI01&midToken=AQHYQWW6cllYNQ&trkEmail=eml-email_pymk_02-pymkCard-0-pymk_cta%3A+urn%3Ali%3Amember%3A601404825-null-awbyzh%7Emhusu3sh%7Eu0-null-null&trk=eml-email_pymk_02-pymkCard-0-pymk_cta%3A+urn%3Ali%3Amember%3A601404825&_sig=1NcYRlv5vbkI0119 mutual connections Junaid Khalid Multi-channel organic marketing for lean startups | CEO @ Ertiqah (makers of LiGo & AudioAI) | Generalist https://www.linkedin.com/comm/mynetwork/send-invite/junaidkhalid22/?lipi=urn%3Ali%3Apage%3Aemail_email_pymk_02%3BuaqwsqVBTnuiga3mlI0Qww%3D%3D&midSig=1SfoNaKTXakI01&midToken=AQHYQWW6cllYNQ&trkEmail=eml-email_pymk_02-pymkCard-0-pymk_cta%3A+urn%3Ali%3Amember%3A535552825-null-awbyzh%7Emhusu3sh%7Eu0-null-null&trk=eml-email_pymk_02-pymkCard-0-pymk_cta%3A+urn%3Ali%3Amember%3A535552825&_sig=04EfSol9vbkI0146 mutual connections Muhammad Roshan Mughees Data Scientist, Generative AI, NLP @ Germanyâ€™s largest comparison marketplace https://www.linkedin.com/comm/mynetwork/send-invite/muhammad-roshan-mughees/?lipi=urn%3Ali%3Apage%3Aemail_email_pymk_02%3BuaqwsqVBTnuiga3mlI0Qww%3D%3D&midSig=1SfoNaKTXakI01&midToken=AQHYQWW6cllYNQ&trkEmail=eml-email_pymk_02-pymkCard-0-pymk_cta%3A+urn%3Ali%3Amember%3A637030674-null-awbyzh%7Emhusu3sh%7Eu0-null-null&trk=eml-email_pymk_02-pymkCard-0-pymk_cta%3A+urn%3Ali%3Amember%3A637030674&_sig=1fEqf2MuvbkI0141 mutual connections See more people you might know:https://www.linkedin.com/comm/mynetwork/add-connections/?lipi=urn%3Ali%3Apage%3Aemail_email_pymk_02%3BuaqwsqVBTnuiga3mlI0Qww%3D%3D&midToken=AQHYQWW6cllYNQ&midSig=1SfoNaKTXakI01&trk=eml-email_pymk_02-see_more-0-cta~text&trkEmail=eml-email_pymk_02-see_more-0-cta~text-null-awbyzh~mhusu3sh~u0-null-null&eid=awbyzh-mhusu3sh-u0&otpToken=MTQwMDE2ZTkxNDI2YzljNmJkMjQwNGVkNDAxY2VmYjM4NmNkZDc0ODkwYTk4YzYxNzdjZjA1Njg0OTViNTVmN2YxZDFkZmEyMTFjMWUzYzcwNGFlZmJkM2FlNjU4YzBmNjA3NTk0MTZlOWI2ODI4ZDQwZGIxZiwxLDE%3D ---------------------------------------- This email was intended for Abdullah Makhdoom (Python | LLM | Gen AI | Data Scientist @ Turing) Learn why we included this: https://www.linkedin.com/help/linkedin/answer/4788?lang=en&lipi=urn%3Ali%3Apage%3Aemail_email_pymk_02%3BuaqwsqVBTnuiga3mlI0Qww%3D%3D&midToken=AQHYQWW6cllYNQ&midSig=1SfoNaKTXakI01&trk=eml-email_pymk_02-SecurityHelp-0-textfooterglimmer&trkEmail=eml-email_pymk_02-SecurityHelp-0-textfooterglimmer-null-awbyzh~mhusu3sh~u0-null-null&eid=awbyzh-mhusu3sh-u0&otpToken=MTQwMDE2ZTkxNDI2YzljNmJkMjQwNGVkNDAxY2VmYjM4NmNkZDc0ODkwYTk4YzYxNzdjZjA1Njg0OTViNTVmN2YxZDFkZmEyMTFjMWUzYzcwNGFlZmJkM2FlNjU4YzBmNjA3NTk0MTZlOWI2ODI4ZDQwZGIxZiwxLDE%3D You are receiving People You May Know notification emails. Unsubscribe: https://www.linkedin.com/comm/psettings/email-unsubscribe?lipi=urn%3Ali%3Apage%3Aemail_email_pymk_02%3BuaqwsqVBTnuiga3mlI0Qww%3D%3D&midToken=AQHYQWW6cllYNQ&midSig=1SfoNaKTXakI01&trk=eml-email_pymk_02-unsubscribe-0-textfooterglimmer&trkEmail=eml-email_pymk_02-unsubscribe-0-textfooterglimmer-null-awbyzh~mhusu3sh~u0-null-null&eid=awbyzh-mhusu3sh-u0&loid=AQGb3atYbLy_NQAAAZpzzJnyFq3WezTU5DFojjP8IgAhn_W7NBPqwlPBOIYand4Une5P5cup9FItHCmztr4YFWNLV0iyo54L0VqUibSeg9F11YVmkvMxDR63 Help: https://www.linkedin.com/help/linkedin/answer/67?lang=en&lipi=urn%3Ali%3Apage%3Aemail_email_pymk_02%3BuaqwsqVBTnuiga3mlI0Qww%3D%3D&midToken=AQHYQWW6cllYNQ&midSig=1SfoNaKTXakI01&trk=eml-email_pymk_02-help-0-textfooterglimmer&trkEmail=eml-email_pymk_02-help-0-textfooterglimmer-null-awbyzh~mhusu3sh~u0-null-null&eid=awbyzh-mhusu3sh-u0&otpToken=MTQwMDE2ZTkxNDI2YzljNmJkMjQwNGVkNDAxY2VmYjM4NmNkZDc0ODkwYTk4YzYxNzdjZjA1Njg0OTViNTVmN2YxZDFkZmEyMTFjMWUzYzcwNGFlZmJkM2FlNjU4YzBmNjA3NTk0MTZlOWI2ODI4ZDQwZGIxZiwxLDE%3D Â© 2025 LinkedIn Corporation, 1zwnj000 West Maude Avenue, Sunnyvale, CA 94085. LinkedIn and the LinkedIn logo are registered trademarks of LinkedIn.\", \"cc\": \"\", \"date\": \"Tuesday, November 11, 2025 at 16:43:00 UTC\", \"from\": \"LinkedIn <messages-noreply@linkedin.com>\", \"header_message_id\": \"<1669214187.4093593.1762879380764@lva1-app84255.prod.linkedin.com>\", \"history_id\": \"4432448\", \"id\": \"19a73f3424226928\", \"in_reply_to\": \"\", \"label_ids\": [\"CATEGORY_SOCIAL\", \"INBOX\"], \"references\": \"\", \"reply_to\": \"\", \"snippet\": \"ML Engineer @ Netsol | MS AI (NUST) | Generative AI: LLMs &amp; Diffusion Í Í Í Í Í Í Í Í Í Í Í Í Í Í Í Í Í Í Í Í Í Í Í Í Í Í Í Í Í Í Í Í Í Í Í Í Í Í Í Í Í Í Í Í Í Í Í Í Í Í Í Í Í Í Í Í Í Í Í Í Í Í Í Í\", \"subject\": \"Rohan Manzoor is someone you may want to connect with\", \"thread_id\": \"19a73f3424226928\", \"to\": \"Abdullah Makhdoom <abdullahmakhdoom1998@gmail.com>\"}]}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here are concise summaries of your 3 latest emails:\n",
      "\n",
      "- Google â€” â€œSecurity alertâ€ (Nov 11, 2025, 19:02 UTC, unread): Notification that Arcade.dev was granted access to your Google Account data. If this wasnâ€™t you, review recent activity and revoke the appâ€™s access in your Google Account security settings.\n",
      "\n",
      "- ASKMigration â€” â€œWhich Canadian City are you most Interested in Abdullah?â€ (Nov 11, 2025, 17:48 UTC, unread): Promotional email about Canadian immigration options, asking you to pick a city (Toronto/Vancouver/Calgary) with CTAs to learn more or start now.\n",
      "\n",
      "- LinkedIn â€” â€œRohan Manzoor is someone you may want to connect withâ€ (Nov 11, 2025, 16:43 UTC): â€œPeople You May Knowâ€ suggestions including Rohan Manzoor and others, with links to connect.\n",
      "\n",
      "Want me to draft a quick response or follow-up for any of these?\n"
     ]
    }
   ],
   "source": [
    "# define a new agent, this time with access to our tool!\n",
    "agent_b = create_agent(\n",
    "    model=\"openai:gpt-5\",\n",
    "    system_prompt=\"You are a helpful assistant that can help with everyday tasks.\"\n",
    "           \" If the user's request is confusing you must ask them to clarify\"\n",
    "           \" their intent, and fulfill the instruction to the best of your\"\n",
    "           \" ability. Be concise and friendly at all times.\"\n",
    "           # It's useful to let the agent know about the tools it has at its disposal.\n",
    "           \" Use the Gmail tools that you have to address requests about emails.\",\n",
    "    tools=[gmail_tool], # we pass the tool we previously authorized.\n",
    "    checkpointer=checkpointer\n",
    ")\n",
    "\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": uuid.uuid4(),\n",
    "        \"user_id\": os.getenv(\"ARCADE_USER_ID\") # When using Arcade tools, we must provide the user_id on the LangGraph config, so Arcade can execute the tool invoked by the agent.\n",
    "    }\n",
    "}\n",
    "print(f'thread_id = {config[\"configurable\"][\"thread_id\"]}')\n",
    "print(f'user_id = {config[\"configurable\"][\"user_id\"]}')\n",
    "\n",
    "# we're using the same prompt we use before, but we're swapping the agent\n",
    "prompt = \"summarize my latest 3 emails please\"\n",
    "user_message = {\"messages\": [HumanMessage(content=prompt)]}\n",
    "run_graph(agent_b, config, user_message)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
